<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Introduction to Geometric Quantum Machine Learning &#8212; Practical Quantum Computing for Scientists 2022.02.24 alpha documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/bootstrap-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/sphinx_highlight.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../../../../_static/js/jquery-1.12.4.min.js"></script>
<script type="text/javascript" src="../../../../_static/js/jquery-fix.js"></script>
<script type="text/javascript" src="../../../../_static/bootstrap-3.4.1/js/bootstrap.min.js"></script>
<script type="text/javascript" src="../../../../_static/bootstrap-sphinx.js"></script>

  </head><body>

  <div id="navbar" class="navbar navbar-inverse navbar-default ">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../../index.html">
          Practical QC for Scientists</a>
        <span class="navbar-text navbar-version pull-left"><b>2022.02.24</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../../../PHYS437/index.html">437</a></li>
                <li><a href="../../index.html">710</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../../../index.html">Contents <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Courses</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../PHYS437/index.html">PHYS 437</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../index.html">PHYS 710</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../archives/archives.html">Archives</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../help/index.html">HOWTOs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../help/IBM_quantum.html">Using IBM quantum Cloud</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="introduction-to-geometric-quantum-machine-learning">
<h1>Introduction to Geometric Quantum Machine Learning<a class="headerlink" href="#introduction-to-geometric-quantum-machine-learning" title="Permalink to this heading">¶</a></h1>
<p>Symmetries are at the heart of physics. Indeed in condensed matter and particle physics we often define a thing simply by the symmetries it adheres to. What does symmetry mean for those in machine learning? In this context the ambition is straightforward — it is a means to reduce the parameter space and improve the trained model’s ability to sucessfully label unseen data, i.e., its ability to generalise.</p>
<p>Suppose we have a learning task and the data we are learning from has an underlying symmetry. For example, consider a game of Noughts and Crosses (aka Tic-tac-toe): if we win a game, we would have won it if the board was rotated or flipped along any of the lines of symmetry. Now if we want to train an algorithm to spot the outcome of these games, we can either ignore the existence of this symmetry or we can somehow include
it. The advantage of paying attention to the symmetry is it identifies multiple configurations of the board as ‘the same thing’ as far as the symmetry is concerned. This means we can reduce our parameter space, and
so the amount of data our algorithm must sift through is immediately reduced. Along the way, the fact that our learning model must encode a symmetry that actually exists in the system we are trying to represent
naturally encourages our results to be more generalisable. The encoding of symmetries into our learning models is where the term <em>equivariance</em> will appear. We will see that demanding that certain symmetries are
included in our models means that the mappings that make up our algorithms must be such that we could transform our input data with respect to a certain symmetry, then apply our mappings, and this would
be the same as applying the mappings and then transforming the output data with the same symmetry. This is the technical property that gives us the name “equavariant learning”.</p>
<p>In classical machine learning, this area is often referred to as geometric deep learning (GDL) due to the traditional association of symmetry to the world of geometry, and the fact that these considerations usually focus on deep neural networks (see Michael M. Bronstein, Joan Bruna, Taco Cohen, Petar Veličković (2021). Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges. arXiv:2104.13478
or Quynh T. Nguyen, Louis Schatzki, Paolo Braccia, Michael Ragone, Patrick J. Coles, Frédéric Sauvage, Martín Larocca, and M. Cerezo (2022). Theory for Equivariant Quantum Neural Networks. arXiv:2210.08566
for a broad introduction). We will refer to the quantum computing version of this as <em>quantum geometric machine learning</em> (QGML).</p>
<section id="representation-theory-in-circuits">
<h2>Representation theory in circuits<a class="headerlink" href="#representation-theory-in-circuits" title="Permalink to this heading">¶</a></h2>
<p>The first thing to discuss is how do we work with symmetries in the first place? The answer lies in the world of group representation theory.</p>
<p>First, let’s define what we mean by a group:</p>
<p><strong>Definition</strong>: A group is a set <span class="math notranslate nohighlight">\(G\)</span> together with a binary operation on
<span class="math notranslate nohighlight">\(G\)</span>, here denoted <span class="math notranslate nohighlight">\(\circ\)</span>, that combines any two elements <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> to
form an element of <span class="math notranslate nohighlight">\(G\)</span>, denoted <span class="math notranslate nohighlight">\(a \circ b\)</span>, such that the following
three requirements, known as group axioms, are satisfied as follows:</p>
<ol class="arabic">
<li><p><strong>Associativity</strong>: For all <span class="math notranslate nohighlight">\(a, b, c\)</span> in <span class="math notranslate nohighlight">\(G\)</span>, one has</p>
<p><span class="math notranslate nohighlight">\((a \circ b) \circ c=a \circ (b \circ c)\)</span>.</p>
</li>
<li><dl class="simple myst">
<dt><strong>Identity element</strong>: There exists an element <span class="math notranslate nohighlight">\(e\)</span> in <span class="math notranslate nohighlight">\(G\)</span> such that, for every <span class="math notranslate nohighlight">\(a\)</span> in <span class="math notranslate nohighlight">\(G\)</span>, one</dt><dd><p>has <span class="math notranslate nohighlight">\(e \circ a=a\)</span> and <span class="math notranslate nohighlight">\(a \circ e=a\)</span>. Such an element is unique.
It is called the identity element of the group.</p>
</dd>
</dl>
</li>
<li><dl class="simple myst">
<dt><strong>Inverse element</strong>: For each <span class="math notranslate nohighlight">\(a\)</span> in <span class="math notranslate nohighlight">\(G\)</span>, there exists an element <span class="math notranslate nohighlight">\(b\)</span> in <span class="math notranslate nohighlight">\(G\)</span></dt><dd><p>such that <span class="math notranslate nohighlight">\(a \circ b=e\)</span> and <span class="math notranslate nohighlight">\(b \circ a=e\)</span>, where <span class="math notranslate nohighlight">\(e\)</span> is the
identity element. For each <span class="math notranslate nohighlight">\(a\)</span>, the element <span class="math notranslate nohighlight">\(b\)</span> is unique: it is
called the inverse of <span class="math notranslate nohighlight">\(a\)</span> and is commonly denoted <span class="math notranslate nohighlight">\(a^{-1}\)</span>.</p>
</dd>
</dl>
</li>
</ol>
<p>With groups defined, we are in a position to articulate what a representation is: Let <span class="math notranslate nohighlight">\(\varphi\)</span> be a map sending <span class="math notranslate nohighlight">\(g\)</span> in group <span class="math notranslate nohighlight">\(G\)</span> to a linear map <span class="math notranslate nohighlight">\(\varphi(g): V \rightarrow V\)</span>, for some vector space <span class="math notranslate nohighlight">\(V\)</span>, which satisfies</p>
<div class="math notranslate nohighlight">
\[\varphi\left(g_{1} g_{2}\right)=\varphi\left(g_{1}\right) \circ \varphi\left(g_{2}\right) \quad \text { for all } g_{1}, g_{2} \in G.\]</div>
<p>The idea here is that just as elements in a group act on each other to reach further elements, i.e., <span class="math notranslate nohighlight">\(g\circ h = k\)</span>, a representation sends us to a mapping acting on a vector space such that <span class="math notranslate nohighlight">\(\varphi(g)\circ \varphi(h) = \varphi(k)\)</span>. In this way we are representing the structure of the group as a linear map. For a representation, our mapping must send us to the general linear group <span class="math notranslate nohighlight">\(GL(n)\)</span> (the space of invertible <span class="math notranslate nohighlight">\(n \times n\)</span> matrices with matrix multiplication as the group multiplication). Note how this is both a group, and by virtue of being a collection of invertible matrices, also a set of linear maps (they’re all invertble matrices that can act on
row vectors). Fundamentally, representation theory is based on the prosaic observation that linear algebra is easy and group theory is abstract. So what if we can study groups via linear maps?</p>
<p>Now due to the importance of unitarity in quantum mechnics, we are particularly interested in the unitary representations: representations where the linear maps are unitary matrices. If we can identify these then we will have a way to naturally encode groups in quantum circuits (which are mostly made up of unitary gates).</p>
<p><img alt="" src="../../../../_images/sphere_equivariant.png" /></p>
<p>How does all this relate to symmetries? Well, a large class of symmetries can be characterised as a group, where all the elements of the group leave some space we are considering unchanged. Let’s consider an example: the symmetries of a sphere. Now when we think of this symmetry we probably think something along the lines of “it’s the same no matter how we rotate it, or flip it left to right, etc”. There is this idea of being invariant under some operation. We also have the idea of being able to undo these actions: if we rotate one way, we can rotate it back. If we flip the sphere right-to-left we can flip it left-to-right to get back to where we started (notice too all these inverses are unique). Trivially we can also do nothing. What exactly are we describing here? We have elements that correspond to an action on a sphere that can be inverted and for which there exists an identity. It is also trivially the case here that if we consider three operations a, b, c from the set of rotations and reflections of the sphere, that if we combine two of them together then <span class="math notranslate nohighlight">\(a\circ (b \circ c) = (a\circ b) \circ c\)</span>. The operations are associative. These features turn out to literally define a group!</p>
<p>As we’ve seen the group in itself is a very abstract creature; this is why we look to its representations. The group labels what symmetries we care about, they tell us the mappings that our system is invariant under, and the unitary representations show us how those symmetries look on a particular space of unitary matrices. If we want to encode the structure of the symmeteries in a quantum circuit we must restrict our gates to being unitary representations of the group.</p>
<p>There remains one question: <em>what is equivariance?</em> With our newfound knowledge of group representation theory we are ready to tackle this. Let <span class="math notranslate nohighlight">\(G\)</span> be our group, and <span class="math notranslate nohighlight">\(V\)</span> and <span class="math notranslate nohighlight">\(W\)</span>, with elements <span class="math notranslate nohighlight">\(v\)</span> and <span class="math notranslate nohighlight">\(w\)</span> respectively, be vector spaces over some field <span class="math notranslate nohighlight">\(F\)</span> with a map <span class="math notranslate nohighlight">\(f\)</span> between them. Suppose we have representations <span class="math notranslate nohighlight">\(\varphi: G \rightarrow GL(V)\)</span> and <span class="math notranslate nohighlight">\(\psi: G \rightarrow GL(W)\)</span>. Furthermore, let’s write <span class="math notranslate nohighlight">\(\varphi_g\)</span> for the representation of <span class="math notranslate nohighlight">\(g\)</span> as a
linear map on <span class="math notranslate nohighlight">\(V\)</span> and <span class="math notranslate nohighlight">\(\psi_g\)</span> as the same group element represented as a linear map on <span class="math notranslate nohighlight">\(W\)</span> respectively. We call <span class="math notranslate nohighlight">\(f\)</span> <em>equivariant</em> if</p>
<div class="math notranslate nohighlight">
\[f(\varphi_g(v))=\psi_g(f(v)) \quad \text { for all } g\in G.\]</div>
<p>The importance of such a map in machine learning is that if, for example, our neural network layers are equivariant maps then two inputs that are related by some intrinsic symmetry (maybe they are reflections) preserve this information in the outputs.</p>
<p>Consider the following figure for example. What we see is a board with a cross in a certain square on the left and some numerical encoding of this on the right, where the 1 is where the X is in the number grid. We
present an equivariant mapping between these two spaces with respect to a group action that is a rotation or a swap (here a <span class="math notranslate nohighlight">\(\pi\)</span> rotation). We can either apply a group action to the original grid and then map to the number grid, or we could map to the number grid and then apply the group action. Equivariance demands that the result of either of these procedures should be the same.</p>
<p><img alt="" src="../../../../_images/equivariant-example.jpg" /></p>
<p>Given the vast amount of input data required to train a neural network the principle that one can pre-encode known symmetry structures into the network allows us to learn better and faster. Indeed it is the reason
for the success of convolutional neural networks (CNNs) for image analysis, where it is known they are equivariant with respect to translations. They naturally encode the idea that a picture of a dog is symmetrically related to the same picture slid to the left by n pixels, and they do this by having neural network layers that are equivariant maps. With our focus on unitary representations (and so quantum circuits) we are looking to extend this idea to quantum machine learning.</p>
</section>
<section id="categories-of-geometric-deep-learning">
<h2>Categories of Geometric Deep Learning<a class="headerlink" href="#categories-of-geometric-deep-learning" title="Permalink to this heading">¶</a></h2>
<p>In Bronstein’s recent book [Bronstein, Bruna, Cohen, Velickovic, Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges (2021), arXix:2104.13478], geometric deep learning is classified into four fundamental categories, as illustrated in the diagram below.</p>
<p><img alt="" src="../../../../_images/gdl-categories.png" /></p>
<p>The grid category captures regularly sampled, or gridded, data such as 2D images. These data would perhaps typically be the purveyance of classical deep learning. However, it is also possible to interpret many of the classical deep learning models in a geometric perspective (such as CNNs an their translational equivariance, as discussed above).</p>
<p>The group category covers homogenous spaces with global symmetries. The canonical example of this category is the sphere (covered in greater detail in our previous article [3]). Spherical data arise in myrad applications, not only when data is acquired directly on the sphere (such as over the Earth or by 360° cameras that capture panoramic photos and videos), but also when considering spherical symmetries (such as in molecular chemistry or magnetic resonance imaging). While the sphere is the most common group setting, other groups and their corresponding symmetries can also be considered.</p>
<p>The graph category covers data that may be represented by a computational graph, with nodes and edges. Networks are well-suited to such representations, hence graph deep learning has found wide application in the study of social networks. The graph approach to geometric deep learning provides great flexibility since much data can be represented by a graph. However, this flexibility can come with a loss in specificity and the advantages that affords. For example, the group setting can often be considered with a graph approach but in this case one loses the underlying knowledge of the group, which can otherwise be leveraged.</p>
<p>The final geodesics and gauges category involves deep learning on more complex shapes, such as more general maniolds and 3D meshes. Such approaches can be of great use in computer vision and graphics, for example, where one can perform deep learning with 3D models and their deformations.</p>
</section>
<section id="noughts-and-crosses">
<h2>Noughts and Crosses<a class="headerlink" href="#noughts-and-crosses" title="Permalink to this heading">¶</a></h2>
<p>Let’s look at the game of noughts and crosses, as inspired by. Two players take turns to place a O or an X, depending on which player they are, in a 3x3 grid. The aim is to get three of your symbols in a row, column, or diagonal. As this is not always possible depending on the choices of the players, there could be a draw. Our learning task is to take a set of completed games labelled with their outcomes and teach the algorithm to identify these correctly.</p>
<p>This board of nine elements has the symmetry of the square, also known as the <em>dihedral group</em>. This means it is symmetric under <span class="math notranslate nohighlight">\(\frac{\pi}{2}\)</span> rotations and flips about the lines of symmetry of a square (vertical, horizontal,and both diagonals).</p>
<p><img alt="" src="../../../../_images/NandC_sym.png" /></p>
<p><strong>The question is, how do we encode this in our QML problem?</strong></p>
<p>First, let us encode this problem classically. We will consider a nine-element vector <span class="math notranslate nohighlight">\(v\)</span>, each element of which identifies a square of the board. The entries themselves can be <span class="math notranslate nohighlight">\(+1\)</span>,<span class="math notranslate nohighlight">\(0\)</span>,<span class="math notranslate nohighlight">\(-1,\)</span> representing a nought, no symbol, or a cross. The label is one-hot encoded in a vector <span class="math notranslate nohighlight">\(y=(y_O,y_- , y_X)\)</span> with <span class="math notranslate nohighlight">\(+1\)</span> in the correct label and <span class="math notranslate nohighlight">\(-1\)</span> in the others. For instance (-1,-1,1) would represent an X in the relevant position.</p>
<p>To create the quantum model let us take nine qubits and let them represent squares of our board. We’ll initialise them all as <span class="math notranslate nohighlight">\(|0\rangle\)</span>, which we note leaves the board invariant under the symmetries of the problem (flip and rotate all you want, it’s still going to be zeroes whatever your mapping). We will then look to apply single qubit <span class="math notranslate nohighlight">\(R_x(\theta)\)</span> rotations on individual qubits, encoding each of the possibilities in the board squares at an angle of <span class="math notranslate nohighlight">\(\frac{2\pi}{3}\)</span> from each other. For our parameterised gates we will have a single-qubit <span class="math notranslate nohighlight">\(R_x(\theta_1)\)</span> and <span class="math notranslate nohighlight">\(R_y(\theta_2)\)</span> rotation at each point. We will then use <span class="math notranslate nohighlight">\(CR_y(\theta_3)\)</span> for two-qubit entangling gates.</p>
<p>This implies that, for each encoding, crudely, we’ll need 18 single-qubit rotation parameters and <span class="math notranslate nohighlight">\(\binom{9}{2}=36\)</span> two-qubit gate rotations. Let’s see how, by using symmetries, we can reduce this.</p>
<p><img alt=".." src="../../../../_images/grid.jpg" /></p>
<p>The indexing of our game board.</p>
<p>The secret will be to encode the symmetries into the gate set so the observables we are interested in inherently respect the symmetries. How do we do this? We need to select the collections of gates that commute with the symmetries. In general, we can use the twirling formula for this:</p>
<p><strong>Tip</strong></p>
<p>Let <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> be the group that encodes our symmetries and <span class="math notranslate nohighlight">\(U\)</span> be a unitary representation of <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. Then,</p>
<div class="math notranslate nohighlight">
\[\mathcal{T}_{U}[X]=\frac{1}{|\mathcal{S}|} \sum_{s \in \mathcal{S}} U(s) X U(s)^{\dagger}\]</div>
<p>defines a projector onto the set of operators commuting with all elements of the representation, i.e.,</p>
<p><span class="math notranslate nohighlight">\(\left[\mathcal{T}_{U}[X], U(s)\right]=\)</span> 0 for all <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(s \in \mathcal{S}\)</span>.</p>
<p>The twirling process applied to an arbitrary unitary will give us a new unitary that commutes with the group as we require. We remember that unitary gates typically have the form <span class="math notranslate nohighlight">\(W = \exp(-i\theta H)\)</span>, where <span class="math notranslate nohighlight">\(H\)</span> is a Hermitian matrix called a <em>generator</em>, and <span class="math notranslate nohighlight">\(\theta\)</span> may be fixed or left as a free parameter. A recipe for creating a unitary that commutes with our symmetries is to <em>twirl the generator of the gate</em>, i.e., we move from the gate <span class="math notranslate nohighlight">\(W = \exp(-i\theta H)\)</span> to the gate <span class="math notranslate nohighlight">\(W' = \exp(-i\theta\mathcal{T}_U[H])\)</span>. When each term in the twirling formula acts on different qubits, then this unitary would further simplify to</p>
<div class="math notranslate nohighlight">
\[W' = \bigotimes_{s\in\mathcal{S}}U(s)\exp(-i\tfrac{\theta}{\vert\mathcal{S}\vert})U(s)^\dagger.\]</div>
<p>For simplicity, we can absorb the normalization factor <span class="math notranslate nohighlight">\(\vert\mathcal{S}\vert\)</span> into the free parameter <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>So let’s look again at our choice of gates: single-qubit <span class="math notranslate nohighlight">\(R_x(\theta)\)</span> and <span class="math notranslate nohighlight">\(R_y(\theta)\)</span> rotations, and entangling two-qubit <span class="math notranslate nohighlight">\(CR_y(\phi)\)</span> gates. What will we get by twirling these?</p>
<p>In this particular instance we can see the action of the twirling operation geometrically as the symmetries involved are all permutations. Let’s consider the <span class="math notranslate nohighlight">\(R_x\)</span> rotation acting on one qubit. Now if this qubit is in the centre location on the grid, then we can flip around any symmetry axis we like, and this operation leaves the qubit invariant, so we’ve identified one equivariant gate immediately. If the qubit is on the corners, then the flipping will send this qubit rotation to each of the other corners. Similarly, if a qubit is on the central edge then the rotation gate will be sent round the other edges. So we can see that the twirling operation is a sum over all the possible outcomes of performing the symmetry action (the sum over the symmetry group actions). Having done this we can see that for a single-qubit rotation the invariant maps are rotations on the central qubit, at all the corners, and at all the central edges (when their rotation angles are fixed to be the same).</p>
<p>As an example consider the following figure, where we take a <span class="math notranslate nohighlight">\(R_x\)</span> gate in the corner and then apply all the symmetries of a square. The result of this twirling leads us to have the same gate at all the corners.</p>
<p><img alt="" src="../../../../_images/twirl.jpeg" /></p>
<p>For entangling gates the situation is similar. There are three invariant classes, the centre entangled with all corners, with all edges, and the edges paired in a ring.</p>
<p>The prediction of a label is obtained via a one-hot-encoding by measuring the expectation values of three invariant observables:</p>
<div class="math notranslate nohighlight">
\[O_{-}=Z_{\text {middle }}=Z_{4}\]</div>
<div class="math notranslate nohighlight">
\[O_{\circ}=\frac{1}{4} \sum_{i \in \text { corners }} Z_{i}=\frac{1}{4}\left[Z_{0}+Z_{2}+Z_{6}+Z_{8}\right]\]</div>
<div class="math notranslate nohighlight">
\[O_{\times}=\frac{1}{4} \sum_{i \in \text { edges }} Z_{i}=\frac{1}{4}\left[Z_{1}+Z_{3}+Z_{5}+Z_{7}\right]\]</div>
<div class="math notranslate nohighlight">
\[\hat{\boldsymbol{y}}=\left(\left\langle O_{\circ}\right\rangle,\left\langle O_{-}\right\rangle,\left\langle O_{\times}\right\rangle\right)\]</div>
<p>This is the quantum encoding of the symmetries into a learning problem. A prediction for a given data point will be obtained by selecting the class for which the observed expectation value is the largest.</p>
<p>Now that we have a specific encoding and have decided on our observables we need to choose a suitable cost function to optimise. We will use an <span class="math notranslate nohighlight">\(l_2\)</span> loss function acting on pairs of games and labels <span class="math notranslate nohighlight">\(D={(g,y)}\)</span>,
where <span class="math notranslate nohighlight">\(D\)</span> is our dataset.</p>
<p>Let’s now implement this!</p>
<p>First let’s generate some games. Here we are creating a small program that will play Noughts and Crosses against itself in a random fashion. On completion, it spits out the winner and the winning board, with noughts as +1, draw as 0, and crosses as -1. There are 26,830 different possible games but we will only sample a few hundred.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># Fix seeds for reproducability</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>

<span class="c1">#  create an empty board</span>
<span class="k">def</span> <span class="nf">create_board</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>


<span class="c1"># Check for empty places on board</span>
<span class="k">def</span> <span class="nf">possibilities</span><span class="p">(</span><span class="n">board</span><span class="p">):</span>
    <span class="n">l</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">board</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">board</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">l</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">l</span>


<span class="c1"># Select a random place for the player</span>
<span class="k">def</span> <span class="nf">random_place</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">):</span>
    <span class="n">selection</span> <span class="o">=</span> <span class="n">possibilities</span><span class="p">(</span><span class="n">board</span><span class="p">)</span>
    <span class="n">current_loc</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">selection</span><span class="p">)</span>
    <span class="n">board</span><span class="p">[</span><span class="n">current_loc</span><span class="p">]</span> <span class="o">=</span> <span class="n">player</span>
    <span class="k">return</span> <span class="n">board</span>


<span class="c1"># Check if there is a winner by having 3 in a row</span>
<span class="k">def</span> <span class="nf">row_win</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">lista</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">win</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
            <span class="n">lista</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">board</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">])</span>

            <span class="k">if</span> <span class="n">board</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span> <span class="o">!=</span> <span class="n">player</span><span class="p">:</span>
                <span class="n">win</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">win</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="k">return</span> <span class="n">win</span>


<span class="c1"># Check if there is a winner by having 3 in a column</span>
<span class="k">def</span> <span class="nf">col_win</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">win</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">board</span><span class="p">[</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span> <span class="o">!=</span> <span class="n">player</span><span class="p">:</span>
                <span class="n">win</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">win</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="k">return</span> <span class="n">win</span>


<span class="c1"># Check if there is a winner by having 3 along a diagonal</span>
<span class="k">def</span> <span class="nf">diag_win</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">):</span>
    <span class="n">win1</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">win2</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)]:</span>
        <span class="k">if</span> <span class="n">board</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span> <span class="o">!=</span> <span class="n">player</span><span class="p">:</span>
            <span class="n">win1</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]:</span>
        <span class="k">if</span> <span class="n">board</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span> <span class="o">!=</span> <span class="n">player</span><span class="p">:</span>
            <span class="n">win2</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">return</span> <span class="n">win1</span> <span class="ow">or</span> <span class="n">win2</span>


<span class="c1"># Check if the win conditions have been met or if a draw has occurred</span>
<span class="k">def</span> <span class="nf">evaluate_game</span><span class="p">(</span><span class="n">board</span><span class="p">):</span>
    <span class="n">winner</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">player</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">row_win</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">)</span> <span class="ow">or</span> <span class="n">col_win</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">)</span> <span class="ow">or</span> <span class="n">diag_win</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">):</span>
            <span class="n">winner</span> <span class="o">=</span> <span class="n">player</span>

    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">board</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">and</span> <span class="n">winner</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">winner</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">return</span> <span class="n">winner</span>


<span class="c1"># Main function to start the game</span>
<span class="k">def</span> <span class="nf">play_game</span><span class="p">():</span>
    <span class="n">board</span><span class="p">,</span> <span class="n">winner</span><span class="p">,</span> <span class="n">counter</span> <span class="o">=</span> <span class="n">create_board</span><span class="p">(),</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">1</span>
    <span class="k">while</span> <span class="n">winner</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">player</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">board</span> <span class="o">=</span> <span class="n">random_place</span><span class="p">(</span><span class="n">board</span><span class="p">,</span> <span class="n">player</span><span class="p">)</span>
            <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">winner</span> <span class="o">=</span> <span class="n">evaluate_game</span><span class="p">(</span><span class="n">board</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">winner</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">break</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">board</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">winner</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">size_for_each_winner</span><span class="p">):</span>
    <span class="n">game_d</span> <span class="o">=</span> <span class="p">{</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="p">[],</span> <span class="mi">0</span><span class="p">:</span> <span class="p">[],</span> <span class="mi">1</span><span class="p">:</span> <span class="p">[]}</span>

    <span class="k">while</span> <span class="nb">min</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">game_d</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span> <span class="o">&lt;</span> <span class="n">size_for_each_winner</span><span class="p">:</span>
        <span class="n">board</span><span class="p">,</span> <span class="n">winner</span> <span class="o">=</span> <span class="n">play_game</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">game_d</span><span class="p">[</span><span class="n">winner</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">size_for_each_winner</span><span class="p">:</span>
            <span class="n">game_d</span><span class="p">[</span><span class="n">winner</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">board</span><span class="p">)</span>

    <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">winner</span><span class="p">,</span> <span class="n">boards</span> <span class="ow">in</span> <span class="n">game_d</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">res</span> <span class="o">+=</span> <span class="p">[(</span><span class="n">board</span><span class="p">,</span> <span class="n">winner</span><span class="p">)</span> <span class="k">for</span> <span class="n">board</span> <span class="ow">in</span> <span class="n">boards</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">res</span>


<span class="n">NUM_TRAINING</span> <span class="o">=</span> <span class="mi">450</span>
<span class="n">NUM_VALIDATION</span> <span class="o">=</span> <span class="mi">600</span>

<span class="c1"># Create datasets but with even numbers of each outcome</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">NUM_TRAINING</span> <span class="o">//</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">dataset_val</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">NUM_VALIDATION</span> <span class="o">//</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s create the relevant circuit expectation values that respect the symmetry classes we defined over the single-site and two-site measurements.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pennylane</span> <span class="k">as</span> <span class="nn">qml</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Set up a nine-qubit system</span>
<span class="n">dev</span> <span class="o">=</span> <span class="n">qml</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;default.qubit.torch&quot;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>

<span class="n">ob_center</span> <span class="o">=</span> <span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">ob_corner</span> <span class="o">=</span> <span class="p">(</span><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span> <span class="o">+</span> <span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ob_edge</span> <span class="o">=</span> <span class="p">(</span><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">+</span> <span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">+</span> <span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">(</span><span class="mi">7</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="mi">4</span><span class="p">)</span>

<span class="c1"># Now let&#39;s encode the data in the following qubit models, first with symmetry</span>
<span class="nd">@qml</span><span class="o">.</span><span class="n">qnode</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">interface</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">circuit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>

    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="c1"># Centre single-qubit rotation</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="c1"># Corner single-qubit rotation</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="c1"># Edge single-qubit rotation</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

    <span class="c1"># Entagling two-qubit gates</span>
    <span class="c1"># circling the edge of the board</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

    <span class="c1"># To the corners from the centre</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>

    <span class="c1"># To the centre from the edges</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">qml</span><span class="o">.</span><span class="n">expval</span><span class="p">(</span><span class="n">ob_center</span><span class="p">),</span> <span class="n">qml</span><span class="o">.</span><span class="n">expval</span><span class="p">(</span><span class="n">ob_corner</span><span class="p">),</span> <span class="n">qml</span><span class="o">.</span><span class="n">expval</span><span class="p">(</span><span class="n">ob_edge</span><span class="p">)]</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">qml</span><span class="o">.</span><span class="n">draw_mpl</span><span class="p">(</span><span class="n">circuit</span><span class="p">)([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">18</span> <span class="o">*</span> <span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/d039d4533ff62ac05e47bc91eb4a2d92626e310356897bee88394adcab6999aa.png" src="../../../../_images/d039d4533ff62ac05e47bc91eb4a2d92626e310356897bee88394adcab6999aa.png" />
</div>
</div>
<p>Let’s also look at the same series of gates but this time they are applied independently from one another, so we won’t be preserving the symmetries with our gate operations. Practically this also means more parameters, as previously groups of gates were updated together.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@qml</span><span class="o">.</span><span class="n">qnode</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">interface</span><span class="o">=</span><span class="s2">&quot;torch&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">circuit_no_sym</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>

    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="c1"># Centre single-qubit rotation</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="c1"># Note in this circuit the parameters aren&#39;t all the same.</span>
    <span class="c1"># Previously they were identical to ensure they were applied</span>
    <span class="c1"># as one combined gate. The fact they can all vary independently</span>
    <span class="c1"># here means we aren&#39;t respecting the symmetry.</span>

    <span class="c1"># Corner single-qubit rotation</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">9</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

    <span class="c1"># Edge single-qubit rotation</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">11</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">12</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">13</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">14</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">15</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">16</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">RY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">17</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

    <span class="c1"># Entagling two-qubit gates</span>
    <span class="c1"># circling the edge of the board</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">18</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">19</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">20</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">21</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">22</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">23</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">24</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">25</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

    <span class="c1"># To the corners from the centre</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">26</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">27</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">28</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">29</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>

    <span class="c1"># To the centre from the edges</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">30</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">31</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">32</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">CRY</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">33</span><span class="p">],</span> <span class="n">wires</span><span class="o">=</span><span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">qml</span><span class="o">.</span><span class="n">expval</span><span class="p">(</span><span class="n">ob_center</span><span class="p">),</span> <span class="n">qml</span><span class="o">.</span><span class="n">expval</span><span class="p">(</span><span class="n">ob_corner</span><span class="p">),</span> <span class="n">qml</span><span class="o">.</span><span class="n">expval</span><span class="p">(</span><span class="n">ob_edge</span><span class="p">)]</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">qml</span><span class="o">.</span><span class="n">draw_mpl</span><span class="p">(</span><span class="n">circuit_no_sym</span><span class="p">)([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">9</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">34</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/d039d4533ff62ac05e47bc91eb4a2d92626e310356897bee88394adcab6999aa.png" src="../../../../_images/d039d4533ff62ac05e47bc91eb4a2d92626e310356897bee88394adcab6999aa.png" />
</div>
</div>
<p>Note again how, though these circuits have a similar form to before, they are parameterised differently. We need to feed the vector <span class="math notranslate nohighlight">\(\boldsymbol{y}\)</span> made up of the expectation value of these three operators into the loss function and use this to update our parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">math</span>

<span class="k">def</span> <span class="nf">encode_game</span><span class="p">(</span><span class="n">game</span><span class="p">):</span>
    <span class="n">board</span><span class="p">,</span> <span class="n">res</span> <span class="o">=</span> <span class="n">game</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">board</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">/</span> <span class="mi">3</span>
    <span class="k">if</span> <span class="n">res</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">res</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
<p>Recall that the loss function we’re interested in is
<span class="math notranslate nohighlight">\(\mathcal{L}(\mathcal{D})=\frac{1}{|\mathcal{D}|} \sum_{(\boldsymbol{g}, \boldsymbol{y}) \in \mathcal{D}}\|\hat{\boldsymbol{y}}(\boldsymbol{g})-\boldsymbol{y}\|_{2}^{2}\)</span>.
We need to define this and then we can begin our optimisation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate the mean square error for this classification problem</span>
<span class="k">def</span> <span class="nf">cost_function</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">circuit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">input</span><span class="p">])</span>
    <span class="n">vec</span> <span class="o">=</span> <span class="n">output</span> <span class="o">-</span> <span class="n">target</span>
    <span class="n">sum_sqr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">vec</span> <span class="o">*</span> <span class="n">vec</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sum_sqr</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s now train our symmetry-preserving circuit on the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">params</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span>
<span class="n">params</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="n">params</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>


<span class="n">max_epoch</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">max_step</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">encoded_dataset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">encode_game</span><span class="p">(</span><span class="n">game</span><span class="p">)</span> <span class="k">for</span> <span class="n">game</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">]))</span>
<span class="n">encoded_dataset_val</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">encode_game</span><span class="p">(</span><span class="n">game</span><span class="p">)</span> <span class="k">for</span> <span class="n">game</span> <span class="ow">in</span> <span class="n">dataset_val</span><span class="p">]))</span>


<span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">y_val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_val</span><span class="p">)</span>
        <span class="n">y_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">circuit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_val</span><span class="p">])</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_out</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">acc</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_val</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;accuracy without training = </span><span class="si">{</span><span class="n">accuracy</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="o">*</span><span class="n">encoded_dataset_val</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">x_dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">encoded_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">y_dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">encoded_dataset</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">saved_costs_sym</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">saved_accs_sym</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_epoch</span><span class="p">):</span>
    <span class="n">rand_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_dataset</span><span class="p">))</span>
    <span class="c1"># Shuffled dataset</span>
    <span class="n">x_dataset</span> <span class="o">=</span> <span class="n">x_dataset</span><span class="p">[</span><span class="n">rand_idx</span><span class="p">]</span>
    <span class="n">y_dataset</span> <span class="o">=</span> <span class="n">y_dataset</span><span class="p">[</span><span class="n">rand_idx</span><span class="p">]</span>

    <span class="n">costs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_step</span><span class="p">):</span>
        <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_dataset</span><span class="p">[</span><span class="n">step</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="p">:</span> <span class="p">(</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_dataset</span><span class="p">[</span><span class="n">step</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="p">:</span> <span class="p">(</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">]</span>

        <span class="k">def</span> <span class="nf">opt_func</span><span class="p">():</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">cost_function</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
            <span class="n">costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">loss</span>

        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">opt_func</span><span class="p">)</span>

    <span class="n">cost</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">costs</span><span class="p">)</span>
    <span class="n">saved_costs_sym</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Compute validation accuracy</span>
        <span class="n">acc_val</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="o">*</span><span class="n">encoded_dataset_val</span><span class="p">)</span>
        <span class="n">saved_accs_sym</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc_val</span><span class="p">)</span>

        <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">acc_val</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch: </span><span class="si">{:2d}</span><span class="s2"> | Loss: </span><span class="si">{:3f}</span><span class="s2"> | Validation accuracy: </span><span class="si">{:3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">res</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>accuracy without training = 0.2383333295583725
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  1 | Loss: 2.996221 | Validation accuracy: 0.153333
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  2 | Loss: 2.838961 | Validation accuracy: 0.415000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  3 | Loss: 2.721652 | Validation accuracy: 0.535000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  4 | Loss: 2.686487 | Validation accuracy: 0.553333
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  5 | Loss: 2.608699 | Validation accuracy: 0.548333
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  6 | Loss: 2.648471 | Validation accuracy: 0.591667
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  7 | Loss: 2.630698 | Validation accuracy: 0.585000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  8 | Loss: 2.544674 | Validation accuracy: 0.585000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  9 | Loss: 2.630653 | Validation accuracy: 0.570000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 10 | Loss: 2.595081 | Validation accuracy: 0.576667
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 11 | Loss: 2.586225 | Validation accuracy: 0.578333
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 12 | Loss: 2.600443 | Validation accuracy: 0.578333
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 13 | Loss: 2.652541 | Validation accuracy: 0.576667
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 14 | Loss: 2.585265 | Validation accuracy: 0.580000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 15 | Loss: 2.598611 | Validation accuracy: 0.580000
</pre></div>
</div>
</div>
</div>
<p>Now we train the non-symmetry preserving circuit.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">34</span><span class="p">)</span>
<span class="n">params</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span><span class="n">params</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>

<span class="c1"># calculate mean square error for this classification problem</span>


<span class="k">def</span> <span class="nf">cost_function_no_sym</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">circuit_no_sym</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">input</span><span class="p">])</span>
    <span class="n">vec</span> <span class="o">=</span> <span class="n">output</span> <span class="o">-</span> <span class="n">target</span>
    <span class="n">sum_sqr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">vec</span> <span class="o">*</span> <span class="n">vec</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sum_sqr</span><span class="p">)</span>


<span class="n">max_epoch</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">max_step</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">15</span>

<span class="n">encoded_dataset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">encode_game</span><span class="p">(</span><span class="n">game</span><span class="p">)</span> <span class="k">for</span> <span class="n">game</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">]))</span>
<span class="n">encoded_dataset_val</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">encode_game</span><span class="p">(</span><span class="n">game</span><span class="p">)</span> <span class="k">for</span> <span class="n">game</span> <span class="ow">in</span> <span class="n">dataset_val</span><span class="p">]))</span>


<span class="k">def</span> <span class="nf">accuracy_no_sym</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">y_val</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_val</span><span class="p">)</span>
        <span class="n">y_out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">circuit_no_sym</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_val</span><span class="p">])</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_out</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_val</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">acc</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_val</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;accuracy without training = </span><span class="si">{</span><span class="n">accuracy_no_sym</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="o">*</span><span class="n">encoded_dataset_val</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="n">x_dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">encoded_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">y_dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">encoded_dataset</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">saved_costs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">saved_accs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_epoch</span><span class="p">):</span>
    <span class="n">rand_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_dataset</span><span class="p">))</span>
    <span class="c1"># Shuffled dataset</span>
    <span class="n">x_dataset</span> <span class="o">=</span> <span class="n">x_dataset</span><span class="p">[</span><span class="n">rand_idx</span><span class="p">]</span>
    <span class="n">y_dataset</span> <span class="o">=</span> <span class="n">y_dataset</span><span class="p">[</span><span class="n">rand_idx</span><span class="p">]</span>

    <span class="n">costs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_step</span><span class="p">):</span>
        <span class="n">x_batch</span> <span class="o">=</span> <span class="n">x_dataset</span><span class="p">[</span><span class="n">step</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="p">:</span> <span class="p">(</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_dataset</span><span class="p">[</span><span class="n">step</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="p">:</span> <span class="p">(</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">]</span>

        <span class="k">def</span> <span class="nf">opt_func</span><span class="p">():</span>
            <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">cost_function_no_sym</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
            <span class="n">costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">loss</span>

        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">opt_func</span><span class="p">)</span>

    <span class="n">cost</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">costs</span><span class="p">)</span>
    <span class="n">saved_costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">costs</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Compute validation accuracy</span>
        <span class="n">acc_val</span> <span class="o">=</span> <span class="n">accuracy_no_sym</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="o">*</span><span class="n">encoded_dataset_val</span><span class="p">)</span>
        <span class="n">saved_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc_val</span><span class="p">)</span>

        <span class="n">res</span> <span class="o">=</span> <span class="p">[</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">acc_val</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch: </span><span class="si">{:2d}</span><span class="s2"> | Loss: </span><span class="si">{:3f}</span><span class="s2"> | Validation accuracy: </span><span class="si">{:3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">res</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>accuracy without training = 0.22166666388511658
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  1 | Loss: 3.025290 | Validation accuracy: 0.235000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  2 | Loss: 2.918151 | Validation accuracy: 0.280000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  3 | Loss: 2.824333 | Validation accuracy: 0.385000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  4 | Loss: 2.747958 | Validation accuracy: 0.501667
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  5 | Loss: 2.693046 | Validation accuracy: 0.466667
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  6 | Loss: 2.659418 | Validation accuracy: 0.446667
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  7 | Loss: 2.641402 | Validation accuracy: 0.460000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  8 | Loss: 2.626516 | Validation accuracy: 0.481667
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  9 | Loss: 2.616884 | Validation accuracy: 0.480000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 10 | Loss: 2.610851 | Validation accuracy: 0.496667
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 11 | Loss: 2.606585 | Validation accuracy: 0.508333
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 12 | Loss: 2.599107 | Validation accuracy: 0.506667
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 13 | Loss: 2.592962 | Validation accuracy: 0.505000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 14 | Loss: 2.589474 | Validation accuracy: 0.515000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 15 | Loss: 2.584630 | Validation accuracy: 0.518333
</pre></div>
</div>
</div>
</div>
<p>Finally let’s plot the results and see how the two training regimes differ.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;seaborn&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Validation accuracies&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">saved_accs_sym</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Symmetric&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">saved_accs</span><span class="p">,</span> <span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Standard&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Validation accuracy (%)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Optimization steps&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_66387/1424843501.py:3: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as &#39;seaborn-v0_8-&lt;style&gt;&#39;. Alternatively, directly use the seaborn API instead.
  plt.style.use(&quot;seaborn&quot;)
</pre></div>
</div>
<img alt="../../../../_images/39401e84913cc69eb00e16b35ea8e87fadaf880a4ca18bbd27b3faf5df89e930.png" src="../../../../_images/39401e84913cc69eb00e16b35ea8e87fadaf880a4ca18bbd27b3faf5df89e930.png" />
</div>
</div>
<p>What we can see then is that by paying attention to the symmetries intrinsic to the learning problem and reflecting this in an equivariant gate set we have managed to improve our learning accuracies, while also
using fewer parameters. While the symmetry-aware circuit clearly outperforms the naive one, it is notable however that the learning accuracies in both cases are hardly ideal given this is a solved game.
So paying attention to symmetries definitely helps, but it also isn’t a magic bullet!</p>
<p>The use of symmetries in both quantum and classsical machine learning is a developing field, so we can expect new results to emerge over the coming years. If you want to get involved, the references given below
are a great place to start.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="send-it-after-class">
<h1>Send it after class:<a class="headerlink" href="#send-it-after-class" title="Permalink to this heading">¶</a></h1>
<p>Use the same approach to predict if a starting configuration in peg solitaire will be an outlier or “genius” (see https://www.cut-the-knot.org/proofs/PegsAndGroups.shtml)</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="the-quantum-graph-recurrent-neural-network">
<h1>The Quantum Graph Recurrent Neural Network<a class="headerlink" href="#the-quantum-graph-recurrent-neural-network" title="Permalink to this heading">¶</a></h1>
<p>This demonstration investigates quantum graph recurrent neural networks (QGRNN), which are the quantum analogue of a classical graph recurrent neural network, and a subclass of the more general quantum graph neural
network ansatz. Both the QGNN and QGRNN were introduced in <a class="reference external" href="https://arxiv.org/abs/1909.12264">this paper (2019)</a>.</p>
<section id="the-idea">
<h2>The Idea<a class="headerlink" href="#the-idea" title="Permalink to this heading">¶</a></h2>
<p>A graph is defined as a set of <em>nodes</em> along with a set of <strong>edges</strong>, which represent connections between nodes. Information can be encoded into graphs by assigning numbers to nodes and edges, which we call
<strong>weights</strong>. It is usually convenient to think of a graph visually:</p>
<p><img alt="image" src="../../../../_images/graph4.png" /></p>
<p>In recent years, the concept of a <a class="reference external" href="https://arxiv.org/abs/1812.08434">graph neural network</a> (GNN) has been receiving a lot of attention from the machine learning community. A GNN seeks to learn a representation (a mapping of data into a low-dimensional vector space) of a given graph with feature vectors assigned to nodes and edges. Each of the vectors in the learned representation preserves not only the features, but also the overall topology of the graph, i.e., which nodes are connected by edges. The quantum graph neural network attempts to do something similar, but for features that are quantum-mechanical; for instance, a collection of quantum states.</p>
<p>Consider the class of qubit Hamiltonians that are <em>quadratic</em>, meaning that the terms of the Hamiltonian represent either interactions between two qubits, or the energy of individual qubits. This class of
Hamiltonians is naturally described by graphs, with second-order terms between qubits corresponding to weighted edges between nodes, and first-order terms corresponding to node weights.</p>
<p>A well known example of a quadratic Hamiltonian is the transverse-field Ising model, which is defined as</p>
<div class="math notranslate nohighlight">
\[\hat{H}_{\text{Ising}}(\boldsymbol\theta) \ = \ \displaystyle\sum_{(i, j) \in E}
\theta_{ij}^{(1)} Z_{i} Z_{j} \ + \ \displaystyle\sum_{i} \theta_{i}^{(2)} Z_{i} \ + \
\displaystyle\sum_{i} X_{i},\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol\theta \ = \ \{\theta^{(1)}, \ \theta^{(2)}\}\)</span>. In this Hamiltonian, the set <span class="math notranslate nohighlight">\(E\)</span> that determines which pairs of qubits have <span class="math notranslate nohighlight">\(ZZ\)</span> interactions can be represented by the set of edges for some graph. With the qubits as nodes, this graph is called the <em>interaction graph</em>. The <span class="math notranslate nohighlight">\(\theta^{(1)}\)</span> parameters correspond to the edge weights and the <span class="math notranslate nohighlight">\(\theta^{(2)}\)</span> parameters correspond to weights on the nodes.</p>
<p>This result implies that we can think about <em>quantum circuits</em> with graph-theoretic properties. Recall that the time-evolution operator with respect to some Hamiltonian <span class="math notranslate nohighlight">\(H\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[U \ = \ e^{-it H}.\]</div>
<p>Thus, we have a clean way of taking quadratic Hamiltonians and turning them into unitaries (quantum circuits) that preserve the same correspondance to a graph. In the case of the Ising Hamiltonian, we have:</p>
<div class="math notranslate nohighlight">
\[
U_{\text{Ising}}  =  e^{-it \hat{H}_{\text{Ising}} (\boldsymbol\theta)}  =  \exp \left[ -it \left( \sum_{(i, j) \in E} \theta_{ij}^{(1)} Z_{i} Z_{j}  +
\sum_{i} \theta_{i}^{(2)} Z_{i}  +  \sum_{i} X_{i} \right) \right]
\]</div>
<p>In general, this kind of unitary is very difficult to implement on a quantum computer. However, we can approximate it using the <a class="reference external" href="https://en.wikipedia.org/wiki/Time-evolving_block_decimation#The_Suzuki-Trotter_expansion">Trotter-Suzuki decomposition</a>:</p>
<div class="math notranslate nohighlight">
\[ \exp \left[ -it \left( \sum_{(i, j) \in E} \theta_{ij}^{(1)} Z_{i} Z_{j}  +
\sum_{i} \theta_{i}^{(2)} Z_{i}  +  \sum_{i} X_{i} \right) \right] \approx \prod_{k \ = \ 1}^{t / \Delta} \left[ \displaystyle\prod_{j  =
1}^{Q} e^{-i \Delta \hat{H}_{\text{Ising}}^{j}(\boldsymbol\theta)} \right]\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{H}_{\text{Ising}}^{j}(\boldsymbol\theta)\)</span> is the <span class="math notranslate nohighlight">\(j\)</span>-th term of the Ising Hamiltonian and <span class="math notranslate nohighlight">\(\Delta\)</span> is some small number.</p>
<p>This circuit is a specific instance of the <strong>Quantum Graph Recurrent Neural Network</strong>, which in general is defined as a variational ansatz of the form</p>
<div class="math notranslate nohighlight">
\[U_{H}(\boldsymbol\mu, \ \boldsymbol\gamma) \ = \ \displaystyle\prod_{i \ = \ 1}^{P} \Bigg[
\displaystyle\prod_{j \ = \ 1}^{Q} e^{-i \gamma_j H^{j}(\boldsymbol\mu)} \Bigg],\]</div>
<p>for some parametrized quadratic Hamiltonian, <span class="math notranslate nohighlight">\(H(\boldsymbol\mu)\)</span>.</p>
</section>
<section id="using-the-qgrnn">
<h2>Using the QGRNN<a class="headerlink" href="#using-the-qgrnn" title="Permalink to this heading">¶</a></h2>
<p>Since the QGRNN ansatz is equivalent to the approximate time evolution of some quadratic Hamiltonian, we can use it to learn the dynamics of a quantum system.</p>
<p>Continuing with the Ising model example, let’s imagine we have some system governed by <span class="math notranslate nohighlight">\(\hat{H}_{\text{Ising}}(\boldsymbol\alpha)\)</span> for an unknown set of target parameters, <span class="math notranslate nohighlight">\(\boldsymbol\alpha\)</span> and an unknown interaction graph <span class="math notranslate nohighlight">\(G\)</span>. Let’s also suppose we have access to copies of some low-energy, non-ground state of the target Hamiltonian, <span class="math notranslate nohighlight">\(|\psi_0\rangle\)</span>. In addition, we have access to a collection of time-evolved states, <span class="math notranslate nohighlight">\(\{ |\psi(t_1)\rangle, \ |\psi(t_2)\rangle, \ ..., \ |\psi(t_N)\rangle \}\)</span>, defined by:</p>
<div class="math notranslate nohighlight">
\[|\psi(t_k)\rangle \ = \ e^{-i t_k \hat{H}_{\text{Ising}}(\boldsymbol\alpha)} |\psi_0\rangle.\]</div>
<p>We call the low-energy states and the collection of time-evolved states <em>quantum data</em>. From here, we randomly pick a number of time-evolved states from our collection. For any state that we choose, which is evolved to some time <span class="math notranslate nohighlight">\(t_k\)</span>, we compare it to</p>
<div class="math notranslate nohighlight">
\[U_{\hat{H}_{\text{Ising}}}(\boldsymbol\mu, \ \Delta) |\psi_0\rangle \ \approx \ e^{-i t_k
\hat{H}_{\text{Ising}}(\boldsymbol\mu)} |\psi_0\rangle.\]</div>
<p>This is done by feeding one of the copies of <span class="math notranslate nohighlight">\(|\psi_0\rangle\)</span> into a quantum circuit with the QGRNN ansatz, with some guessed set of parameters <span class="math notranslate nohighlight">\(\boldsymbol\mu\)</span> and a guessed interaction graph, <span class="math notranslate nohighlight">\(G'\)</span>. We then use a classical optimizer to maximize the average “similarity” between the time-evolved states and the states prepared with the QGRNN.</p>
<p>As the QGRNN states becomes more similar to each time-evolved state for each sampled time, it follows that <span class="math notranslate nohighlight">\(\boldsymbol\mu \ \rightarrow \ \boldsymbol\alpha\)</span> and we are able to learn the unknown parameters of the Hamiltonian.</p>
<p><img alt="A visual representation of one execution of the QGRNN for one piece ofquantum data." src="../../../../_images/qgrnn3.png" /></p>
</section>
<section id="learning-an-ising-model-with-the-qgrnn">
<h2>Learning an Ising Model with the QGRNN<a class="headerlink" href="#learning-an-ising-model-with-the-qgrnn" title="Permalink to this heading">¶</a></h2>
<p>We now attempt to use the QGRNN to learn the parameters corresponding to an arbitrary transverse-field Ising model Hamiltonian.</p>
</section>
<section id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this heading">¶</a></h2>
<p>We begin by importing the necessary dependencies:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pennylane</span> <span class="k">as</span> <span class="nn">qml</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">pennylane</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">copy</span>
</pre></div>
</div>
</div>
</div>
<p>We also define some fixed values that are used throughout the simulation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">qubit_number</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">qubits</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">qubit_number</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In this simulation, we don’t have quantum data readily available to pass into the QGRNN, so we have to generate it ourselves. To do this, we must have knowledge of the target interaction graph and the target Hamiltonian.</p>
<p>Let us use the following cyclic graph as the target interaction graph of the Ising Hamiltonian:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ising_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">cycle_graph</span><span class="p">(</span><span class="n">qubit_number</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Edges: </span><span class="si">{</span><span class="n">ising_graph</span><span class="o">.</span><span class="n">edges</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">ising_graph</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Edges: [(0, 1), (0, 3), (1, 2), (2, 3)]
</pre></div>
</div>
<img alt="../../../../_images/91e4044ffb98e9bf6ba2442b198e47d23ff4a8db38c638849d0aff7932be0d58.png" src="../../../../_images/91e4044ffb98e9bf6ba2442b198e47d23ff4a8db38c638849d0aff7932be0d58.png" />
</div>
</div>
<p>We can then initialize the “unknown” target parameters that describe the target Hamiltonian,</p>
<p><span class="math notranslate nohighlight">\(\boldsymbol\alpha \ = \ \{\alpha^{(1)}, \ \alpha^{(2)}\}\)</span>. Recall from</p>
<p>the introduction that we have defined our parametrized Ising Hamiltonian to be of the form:</p>
<div class="math notranslate nohighlight">
\[\hat{H}_{\text{Ising}}(\boldsymbol\theta)  =  \sum_{(i, j) \in E}
\theta_{ij}^{(1)} Z_{i} Z_{j}  +  \sum_{i} \theta_{i}^{(2)} Z_{i}  +
\sum_{i} X_{i},\]</div>
<p>where <span class="math notranslate nohighlight">\(E\)</span> is the set of edges in the interaction graph, and <span class="math notranslate nohighlight">\(X_i\)</span> and <span class="math notranslate nohighlight">\(Z_i\)</span> are the Pauli-X and Pauli-Z on the <span class="math notranslate nohighlight">\(i\)</span>-th qubit.</p>
<p>For this tutorial, we choose the target parameters by sampling from a uniform probability distribution ranging from <span class="math notranslate nohighlight">\(-2\)</span> to <span class="math notranslate nohighlight">\(2\)</span>, with
two-decimal precision.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">target_weights</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.56</span><span class="p">,</span> <span class="mf">1.24</span><span class="p">,</span> <span class="mf">1.67</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.79</span><span class="p">]</span>
<span class="n">target_bias</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.44</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.43</span><span class="p">,</span> <span class="mf">1.18</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.93</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>In theory, these parameters can be any value we want, provided they are reasonably small enough that the QGRNN can reach them in a tractable number of optimization steps. In <code class="docutils literal notranslate"><span class="pre">matrix_params</span></code>, the first list represents the <span class="math notranslate nohighlight">\(ZZ\)</span> interaction parameters and the second list represents the single-qubit <span class="math notranslate nohighlight">\(Z\)</span> parameters.</p>
<p>Finally, we use this information to generate the matrix form of the Ising model Hamiltonian in the computational basis:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_hamiltonian_matrix</span><span class="p">(</span><span class="n">n_qubits</span><span class="p">,</span> <span class="n">graph</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">):</span>

    <span class="n">full_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span> <span class="o">**</span> <span class="n">n_qubits</span><span class="p">,</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">n_qubits</span><span class="p">))</span>

    <span class="c1"># Creates the interaction component of the Hamiltonian</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">edge</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">edges</span><span class="p">):</span>
        <span class="n">interaction_term</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">qubit</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">qubit</span> <span class="ow">in</span> <span class="n">edge</span><span class="p">:</span>
                <span class="n">interaction_term</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">interaction_term</span><span class="p">,</span> <span class="n">qml</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">)(</span><span class="mi">0</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">interaction_term</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">interaction_term</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">full_matrix</span> <span class="o">+=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">interaction_term</span>

    <span class="c1"># Creates the bias components of the matrix</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">):</span>
        <span class="n">z_term</span> <span class="o">=</span> <span class="n">x_term</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_qubits</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="n">i</span><span class="p">:</span>
                <span class="n">z_term</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">z_term</span><span class="p">,</span> <span class="n">qml</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">)(</span><span class="mi">0</span><span class="p">))</span>
                <span class="n">x_term</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">x_term</span><span class="p">,</span> <span class="n">qml</span><span class="o">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">qml</span><span class="o">.</span><span class="n">PauliX</span><span class="p">)(</span><span class="mi">0</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">z_term</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">z_term</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
                <span class="n">x_term</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">x_term</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">full_matrix</span> <span class="o">+=</span> <span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">z_term</span> <span class="o">+</span> <span class="n">x_term</span>

    <span class="k">return</span> <span class="n">full_matrix</span>


<span class="c1"># Prints a visual representation of the Hamiltonian matrix</span>
<span class="n">ham_matrix</span> <span class="o">=</span> <span class="n">create_hamiltonian_matrix</span><span class="p">(</span><span class="n">qubit_number</span><span class="p">,</span> <span class="n">ising_graph</span><span class="p">,</span> <span class="n">target_weights</span><span class="p">,</span> <span class="n">target_bias</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">ham_matrix</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;hot&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/51937cf245a962ac796a2bccb88d4b25201628cf4d6e5864312ef67b1d611591.png" src="../../../../_images/51937cf245a962ac796a2bccb88d4b25201628cf4d6e5864312ef67b1d611591.png" />
</div>
</div>
</section>
<section id="preparing-quantum-data">
<h2>Preparing Quantum Data<a class="headerlink" href="#preparing-quantum-data" title="Permalink to this heading">¶</a></h2>
<p>The collection of quantum data needed to run the QGRNN has two components: (i) copies of a low-energy state, and (ii) a collection of time-evolved states, each of which are simply the low-energy state evolved to different times. The following is a low-energy state of the target Hamiltonian:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">low_energy_state</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="o">-</span><span class="mf">0.054661080280306085</span> <span class="o">+</span> <span class="mf">0.016713907320174026</span><span class="n">j</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.12290003656489545</span> <span class="o">-</span> <span class="mf">0.03758500591109822</span><span class="n">j</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.3649337966440005</span> <span class="o">-</span> <span class="mf">0.11158863596657455</span><span class="n">j</span><span class="p">),</span>
    <span class="p">(</span><span class="o">-</span><span class="mf">0.8205175732627094</span> <span class="o">+</span> <span class="mf">0.25093231967092877</span><span class="n">j</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.010369790825776609</span> <span class="o">-</span> <span class="mf">0.0031706387262686003</span><span class="n">j</span><span class="p">),</span>
    <span class="p">(</span><span class="o">-</span><span class="mf">0.02331544978544721</span> <span class="o">+</span> <span class="mf">0.007129899300113728</span><span class="n">j</span><span class="p">),</span>
    <span class="p">(</span><span class="o">-</span><span class="mf">0.06923183949694546</span> <span class="o">+</span> <span class="mf">0.0211684344103713</span><span class="n">j</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.15566094863283836</span> <span class="o">-</span> <span class="mf">0.04760201916285508</span><span class="n">j</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.014520590919500158</span> <span class="o">-</span> <span class="mf">0.004441887836078486</span><span class="n">j</span><span class="p">),</span>
    <span class="p">(</span><span class="o">-</span><span class="mf">0.032648113364535575</span> <span class="o">+</span> <span class="mf">0.009988590222879195</span><span class="n">j</span><span class="p">),</span>
    <span class="p">(</span><span class="o">-</span><span class="mf">0.09694382811137187</span> <span class="o">+</span> <span class="mf">0.02965579457620536</span><span class="n">j</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.21796861485652747</span> <span class="o">-</span> <span class="mf">0.06668776658411019</span><span class="n">j</span><span class="p">),</span>
    <span class="p">(</span><span class="o">-</span><span class="mf">0.0027547112135013247</span> <span class="o">+</span> <span class="mf">0.0008426289322652901</span><span class="n">j</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.006193695872468649</span> <span class="o">-</span> <span class="mf">0.0018948418969390599</span><span class="n">j</span><span class="p">),</span>
    <span class="p">(</span><span class="mf">0.018391279795405405</span> <span class="o">-</span> <span class="mf">0.005625722994009138</span><span class="n">j</span><span class="p">),</span>
    <span class="p">(</span><span class="o">-</span><span class="mf">0.041350974715649635</span> <span class="o">+</span> <span class="mf">0.012650711602265649</span><span class="n">j</span><span class="p">),</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>This state can be obtained by using a decoupled version of the <code class="docutils literal notranslate"><span class="pre">Variational</span> <span class="pre">Quantum</span> <span class="pre">Eigensolver</span></code> algorithm (VQE). Essentially, we choose a VQE ansatz such that the circuit cannot learn the exact ground state, but it can get
fairly close. Another way to arrive at the same result is to perform VQE with a reasonable ansatz, but to terminate the algorithm before it converges to the ground state. If we used the exact ground state <span class="math notranslate nohighlight">\(|\psi_0\rangle\)</span>, the time-dependence would be trivial and the data would not provide enough information about the Hamiltonian parameters.</p>
<p>We can verify that this is a low-energy state by numerically finding the lowest eigenvalue of the Hamiltonian and comparing it to the energy expectation of this low-energy state:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vdot</span><span class="p">(</span><span class="n">low_energy_state</span><span class="p">,</span> <span class="p">(</span><span class="n">ham_matrix</span> <span class="o">@</span> <span class="n">low_energy_state</span><span class="p">))</span>
<span class="n">energy_exp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">real_if_close</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Energy Expectation: </span><span class="si">{</span><span class="n">energy_exp</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="n">ground_state_energy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">real_if_close</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">ham_matrix</span><span class="p">)[</span><span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ground State Energy: </span><span class="si">{</span><span class="n">ground_state_energy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Energy Expectation: -7.244508985189116
Ground State Energy: -7.330689661291244
</pre></div>
</div>
</div>
</div>
<p>We have in fact found a low-energy, non-ground state, as the energy expectation is slightly greater than the energy of the true ground state. This, however, is only half of the information we need. We also require a collection of time-evolved, low-energy states. Evolving the low-energy state forward in time is fairly straightforward: all we have to do is multiply the initial state by a time-evolution unitary. This operation can be defined as a custom gate in PennyLane:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">state_evolve</span><span class="p">(</span><span class="n">hamiltonian</span><span class="p">,</span> <span class="n">qubits</span><span class="p">,</span> <span class="n">time</span><span class="p">):</span>

    <span class="n">U</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">expm</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="n">j</span> <span class="o">*</span> <span class="n">hamiltonian</span> <span class="o">*</span> <span class="n">time</span><span class="p">)</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">QubitUnitary</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">qubits</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We don’t actually generate time-evolved quantum data quite yet, but we now have all the pieces required for its preparation.</p>
</section>
<section id="learning-the-hamiltonian">
<h2>Learning the Hamiltonian<a class="headerlink" href="#learning-the-hamiltonian" title="Permalink to this heading">¶</a></h2>
<p>With the quantum data defined, we are able to construct the QGRNN and learn the target Hamiltonian. Each of the exponentiated Hamiltonians in the QGRNN ansatz, <span class="math notranslate nohighlight">\(\hat{H}^{j}_{\text{Ising}}(\boldsymbol\mu)\)</span>, are the <span class="math notranslate nohighlight">\(ZZ\)</span>, <span class="math notranslate nohighlight">\(Z\)</span>, and <span class="math notranslate nohighlight">\(X\)</span> terms from the Ising Hamiltonian. This gives:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">qgrnn_layer</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">qubits</span><span class="p">,</span> <span class="n">graph</span><span class="p">,</span> <span class="n">trotter_step</span><span class="p">):</span>

    <span class="c1"># Applies a layer of RZZ gates (based on a graph)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">edge</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">edges</span><span class="p">):</span>
        <span class="n">qml</span><span class="o">.</span><span class="n">MultiRZ</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">trotter_step</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="p">(</span><span class="n">edge</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">edge</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

    <span class="c1"># Applies a layer of RZ gates</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">qubit</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">qubits</span><span class="p">):</span>
        <span class="n">qml</span><span class="o">.</span><span class="n">RZ</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">bias</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">trotter_step</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">qubit</span><span class="p">)</span>

    <span class="c1"># Applies a layer of RX gates</span>
    <span class="k">for</span> <span class="n">qubit</span> <span class="ow">in</span> <span class="n">qubits</span><span class="p">:</span>
        <span class="n">qml</span><span class="o">.</span><span class="n">RX</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">trotter_step</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="n">qubit</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As was mentioned in the first section, the QGRNN has two registers. In one register, some piece of quantum data <span class="math notranslate nohighlight">\(|\psi(t)\rangle\)</span> is prepared and in the other we have <span class="math notranslate nohighlight">\(U_{H}(\boldsymbol\mu, \ \Delta) |\psi_0\rangle\)</span>. We need a way to measure the similarity between these states. This can be done by using the fidelity, which is simply the modulus squared of the inner product between the states, <span class="math notranslate nohighlight">\(| \langle \psi(t) | U_{H}(\Delta, \ \boldsymbol\mu) |\psi_0\rangle |^2\)</span>.</p>
<p>To calculate this value, we use a <a class="reference external" href="https://en.wikipedia.org/wiki/Swap_test">SWAP test</a> between the registers:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">swap_test</span><span class="p">(</span><span class="n">control</span><span class="p">,</span> <span class="n">register1</span><span class="p">,</span> <span class="n">register2</span><span class="p">):</span>

    <span class="n">qml</span><span class="o">.</span><span class="n">Hadamard</span><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="n">control</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">reg1_qubit</span><span class="p">,</span> <span class="n">reg2_qubit</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">register1</span><span class="p">,</span> <span class="n">register2</span><span class="p">):</span>
        <span class="n">qml</span><span class="o">.</span><span class="n">CSWAP</span><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="p">(</span><span class="n">control</span><span class="p">,</span> <span class="n">reg1_qubit</span><span class="p">,</span> <span class="n">reg2_qubit</span><span class="p">))</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">Hadamard</span><span class="p">(</span><span class="n">wires</span><span class="o">=</span><span class="n">control</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>After performing this procedure, the value returned from a measurement of the circuit is <span class="math notranslate nohighlight">\(\langle Z \rangle\)</span>, with respect to the <code class="docutils literal notranslate"><span class="pre">control</span></code> qubit. The probability of measuring the <span class="math notranslate nohighlight">\(|0\rangle\)</span> state in this control qubit is related to both the fidelity between registers and <span class="math notranslate nohighlight">\(\langle Z \rangle\)</span>. Thus, with a bit of algebra, we find that <span class="math notranslate nohighlight">\(\langle Z \rangle\)</span> is equal to the fidelity.</p>
<p>Before creating the full QGRNN and the cost function, we define a few more fixed values. Among these is a “guessed” interaction graph, which we set to be a <a class="reference external" href="https://en.wikipedia.org/wiki/Complete_graph">complete graph</a>. This choice is motivated by the fact that any target interaction graph will be a subgraph of this initial guess. Part of the idea behind the QGRNN is that we don’t know the interaction graph, and it has to be learned. In this case, the graph is learned <em>automatically</em> as the target parameters are optimized. The <span class="math notranslate nohighlight">\(\boldsymbol\mu\)</span> parameters that correspond to edges that don’t exist in the target graph will simply approach <span class="math notranslate nohighlight">\(0\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Defines some fixed values</span>

<span class="n">reg1</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">qubit_number</span><span class="p">))</span>  <span class="c1"># First qubit register</span>
<span class="n">reg2</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">qubit_number</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">qubit_number</span><span class="p">))</span>  <span class="c1"># Second qubit register</span>

<span class="n">control</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">qubit_number</span>  <span class="c1"># Index of control qubit</span>
<span class="n">trotter_step</span> <span class="o">=</span> <span class="mf">0.01</span>  <span class="c1"># Trotter step size</span>

<span class="c1"># Defines the interaction graph for the new qubit system</span>

<span class="n">new_ising_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">complete_graph</span><span class="p">(</span><span class="n">reg2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Edges: </span><span class="si">{</span><span class="n">new_ising_graph</span><span class="o">.</span><span class="n">edges</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">new_ising_graph</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Edges: [(4, 5), (4, 6), (4, 7), (5, 6), (5, 7), (6, 7)]
</pre></div>
</div>
<img alt="../../../../_images/30ded45c2738221fa3404db054058790a6e174da9f2761933aec6c5e06702659.png" src="../../../../_images/30ded45c2738221fa3404db054058790a6e174da9f2761933aec6c5e06702659.png" />
</div>
</div>
<p>With this done, we implement the QGRNN circuit for some given time value:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">qgrnn</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">time</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

    <span class="c1"># Prepares the low energy state in the two registers</span>
    <span class="n">qml</span><span class="o">.</span><span class="n">QubitStateVector</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">kron</span><span class="p">(</span><span class="n">low_energy_state</span><span class="p">,</span> <span class="n">low_energy_state</span><span class="p">),</span> <span class="n">wires</span><span class="o">=</span><span class="n">reg1</span> <span class="o">+</span> <span class="n">reg2</span><span class="p">)</span>

    <span class="c1"># Evolves the first qubit register with the time-evolution circuit to</span>
    <span class="c1"># prepare a piece of quantum data</span>
    <span class="n">state_evolve</span><span class="p">(</span><span class="n">ham_matrix</span><span class="p">,</span> <span class="n">reg1</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>

    <span class="c1"># Applies the QGRNN layers to the second qubit register</span>
    <span class="n">depth</span> <span class="o">=</span> <span class="n">time</span> <span class="o">/</span> <span class="n">trotter_step</span>  <span class="c1"># P = t/Delta</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">depth</span><span class="p">)):</span>
        <span class="n">qgrnn_layer</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">reg2</span><span class="p">,</span> <span class="n">new_ising_graph</span><span class="p">,</span> <span class="n">trotter_step</span><span class="p">)</span>

    <span class="c1"># Applies the SWAP test between the registers</span>
    <span class="n">swap_test</span><span class="p">(</span><span class="n">control</span><span class="p">,</span> <span class="n">reg1</span><span class="p">,</span> <span class="n">reg2</span><span class="p">)</span>

    <span class="c1"># Returns the results of the SWAP test</span>
    <span class="k">return</span> <span class="n">qml</span><span class="o">.</span><span class="n">expval</span><span class="p">(</span><span class="n">qml</span><span class="o">.</span><span class="n">PauliZ</span><span class="p">(</span><span class="n">control</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>We have the full QGRNN circuit, but we still need to define a cost function. We know that <span class="math notranslate nohighlight">\(| \langle \psi(t) | U_{H}(\boldsymbol\mu, \ \Delta) |\psi_0\rangle |^2\)</span>
approaches <span class="math notranslate nohighlight">\(1\)</span> as the states become more similar and approaches <span class="math notranslate nohighlight">\(0\)</span> as the states become orthogonal. Thus, we choose to minimize the quantity <span class="math notranslate nohighlight">\(-| \langle \psi(t) | U_{H}(\boldsymbol\mu, \ \Delta) |\psi_0\rangle |^2\)</span>.
Since we are interested in calculating this value for many different pieces of quantum data, the final cost function is the average negative fidelity* between registers:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(\boldsymbol\mu, \ \Delta) \ = \ - \frac{1}{N} \displaystyle\sum_{i \ = \ 1}^{N} | \langle \psi(t_i) | \ U_{H}(\boldsymbol\mu, \ \Delta) \ |\psi_0\rangle |^2,\]</div>
<p>where we use <span class="math notranslate nohighlight">\(N\)</span> pieces of quantum data.</p>
<p>Before creating the cost function, we must define a few more fixed variables:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">15</span>  <span class="c1"># The number of pieces of quantum data that are used for each step</span>
<span class="n">max_time</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># The maximum value of time that can be used for quantum data</span>
</pre></div>
</div>
</div>
</div>
<p>We then define the negative fidelity cost function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">cost_function</span><span class="p">(</span><span class="n">weight_params</span><span class="p">,</span> <span class="n">bias_params</span><span class="p">):</span>

    <span class="c1"># Randomly samples times at which the QGRNN runs</span>
    <span class="n">times_sampled</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span> <span class="o">*</span> <span class="n">max_time</span>

    <span class="c1"># Cycles through each of the sampled times and calculates the cost</span>
    <span class="n">total_cost</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">dt</span> <span class="ow">in</span> <span class="n">times_sampled</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">qgrnn_qnode</span><span class="p">(</span><span class="n">weight_params</span><span class="p">,</span> <span class="n">bias_params</span><span class="p">,</span> <span class="n">time</span><span class="o">=</span><span class="n">dt</span><span class="p">)</span>
        <span class="n">total_cost</span> <span class="o">+=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">result</span>

    <span class="k">return</span> <span class="n">total_cost</span> <span class="o">/</span> <span class="n">N</span>
</pre></div>
</div>
</div>
</div>
<p>Next we set up for optimization.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Defines the new device</span>
<span class="n">qgrnn_dev</span> <span class="o">=</span> <span class="n">qml</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;default.qubit&quot;</span><span class="p">,</span> <span class="n">wires</span><span class="o">=</span><span class="mi">2</span> <span class="o">*</span> <span class="n">qubit_number</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Defines the new QNode</span>
<span class="n">qgrnn_qnode</span> <span class="o">=</span> <span class="n">qml</span><span class="o">.</span><span class="n">QNode</span><span class="p">(</span><span class="n">qgrnn</span><span class="p">,</span> <span class="n">qgrnn_dev</span><span class="p">)</span>

<span class="n">steps</span> <span class="o">=</span> <span class="mi">300</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">qml</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">stepsize</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">weights</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">new_ising_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">qubit_number</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span>

<span class="n">initial_weights</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
<span class="n">initial_bias</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">bias</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>All that remains is executing the optimization loop.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">steps</span><span class="p">):</span>
    <span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">),</span> <span class="n">cost</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">step_and_cost</span><span class="p">(</span><span class="n">cost_function</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>

    <span class="c1"># Prints the value of the cost function</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cost at Step </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">cost</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Weights at Step </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">weights</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Bias at Step </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">bias</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---------------------------------------------&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 0: -0.9803638573791906
Weights at Step 0: [-0.22603613  0.43887001  0.85859236  0.69735898  0.09417125 -0.02437147]
Bias at Step 0: [-0.23884748 -0.21392016  0.12809368  0.45037793]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 5: -0.997458952442803
Weights at Step 5: [-0.75106068  1.078707    0.83766935  1.9741555   0.04982793 -0.06747815]
Bias at Step 5: [-0.50836435 -1.32708118  1.57468372  0.11442806]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 10: -0.9971878268304797
Weights at Step 10: [ 0.01577799  0.48771566  0.68379977  1.75747002 -0.21948418 -0.00484698]
Bias at Step 10: [ 0.22007905 -0.90282076  1.58989008 -0.1051542 ]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 15: -0.9981871533122741
Weights at Step 15: [-0.06744249  0.65720464  1.31471457  1.47430241  0.05813038 -0.41315658]
Bias at Step 15: [-0.29045223 -0.67045595  1.19395446  0.24677711]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 20: -0.9995130692146869
Weights at Step 20: [-0.16225009  0.66208813  1.17758061  1.48254064 -0.35468207 -0.01648733]
Bias at Step 20: [-0.56832881 -0.87721581  0.86890622 -0.27734217]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 25: -0.9998181560069559
Weights at Step 25: [ 0.030689    0.40363412  1.32430282  1.80692972 -0.14761078 -0.27452275]
Bias at Step 25: [-0.33695681 -1.28646051  1.00509121 -0.19672993]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 30: -0.9997713453918133
Weights at Step 30: [ 0.22014178  0.38063046  1.34934589  1.82854127 -0.201276   -0.35610913]
Bias at Step 30: [-0.40515586 -1.19466624  1.13933672 -0.31753371]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 35: -0.9997858632135159
Weights at Step 35: [ 0.22310889  0.50896099  1.36029033  1.73588161 -0.30076632 -0.35201799]
Bias at Step 35: [-0.73605504 -1.06150682  1.07911402 -0.49331792]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 40: -0.9998587245201027
Weights at Step 40: [ 0.32580831  0.34293483  1.38813471  1.76261455 -0.16880133 -0.49831078]
Bias at Step 40: [-0.74534508 -1.20379495  0.91916721 -0.49099848]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 45: -0.9998796449154707
Weights at Step 45: [ 0.37151473  0.26329833  1.29149206  1.84754531 -0.16287055 -0.51793342]
Bias at Step 45: [-0.81082195 -1.35860008  0.88788716 -0.63818331]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 50: -0.9999381279674817
Weights at Step 50: [ 0.36839385  0.36200243  1.3398256   1.82138962 -0.10863003 -0.63499473]
Bias at Step 50: [-1.04909977 -1.27581779  0.93902928 -0.67286639]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 55: -0.9999252881391635
Weights at Step 55: [ 0.52717503  0.22669791  1.27477846  1.75733597 -0.1195999  -0.66147384]
Bias at Step 55: [-1.02458911 -1.19668936  0.89787258 -0.76851797]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 60: -0.9999298586216633
Weights at Step 60: [ 0.46426344  0.2377941   1.30579533  1.86309089 -0.05164041 -0.72495523]
Bias at Step 60: [-1.15189323 -1.3565901   0.92299357 -0.81716179]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 65: -0.9999633163685122
Weights at Step 65: [ 0.54814165  0.15321249  1.29421602  1.79468038 -0.06551864 -0.73442872]
Bias at Step 65: [-1.18093812 -1.2850757   0.8715214  -0.89498456]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 70: -0.9999692974112367
Weights at Step 70: [ 0.54968362  0.15363051  1.32636004  1.81799545 -0.03795287 -0.78176424]
Bias at Step 70: [-1.26004878 -1.29186174  0.93275685 -0.93151559]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 75: -0.9999839418035987
Weights at Step 75: [ 0.56926778  0.09899053  1.32784104  1.83800055 -0.02258999 -0.80100631]
Bias at Step 75: [-1.27844754 -1.32707392  0.95121289 -0.97776518]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 80: -0.9999900754964176
Weights at Step 80: [ 0.58436296  0.06469565  1.33177097  1.80638755 -0.0264562  -0.80504093]
Bias at Step 80: [-1.32003524 -1.30314422  0.93367031 -1.02093595]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 85: -0.9999892005586408
Weights at Step 85: [ 5.76118484e-01  5.92975577e-02  1.35458994e+00  1.82562544e+00
 -6.90843714e-04 -8.37859294e-01]
Bias at Step 85: [-1.35783384 -1.32173749  0.97374052 -1.02956436]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 90: -0.9999860418671421
Weights at Step 90: [ 0.60406684  0.01793718  1.33218637  1.81633306 -0.0189833  -0.82575128]
Bias at Step 90: [-1.35074923 -1.31381294  0.98189172 -1.07270478]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 95: -0.9999837519650678
Weights at Step 95: [ 0.58241323  0.02570679  1.35041725  1.81039596  0.00900262 -0.85399323]
Bias at Step 95: [-1.39511753 -1.32055157  0.98642234 -1.06137202]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 100: -0.9999862374755373
Weights at Step 100: [ 0.59133649  0.00671959  1.33149619  1.80654252  0.00739735 -0.85271751]
Bias at Step 100: [-1.3928395  -1.32434117  0.99986843 -1.0746036 ]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 105: -0.9999860417314501
Weights at Step 105: [ 5.98294601e-01 -1.63872117e-03  1.32435903e+00  1.79606830e+00
 -1.50600209e-03 -8.46854780e-01]
Bias at Step 105: [-1.39810406 -1.31716394  1.00632966 -1.08694727]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 110: -0.9999889448376538
Weights at Step 110: [ 0.58790075  0.00252021  1.34070893  1.79969067  0.01353978 -0.86073241]
Bias at Step 110: [-1.41237809 -1.33237829  1.01344356 -1.07306401]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 115: -0.9999907527375036
Weights at Step 115: [ 0.59511523 -0.00485992  1.33269226  1.79443191  0.00548165 -0.85246429]
Bias at Step 115: [-1.40713813 -1.33369881  1.02023634 -1.07811166]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 120: -0.9999894991115474
Weights at Step 120: [ 5.96065192e-01 -3.92737036e-03  1.33288381e+00  1.78858855e+00
  1.75644333e-03 -8.48477853e-01]
Bias at Step 120: [-1.40998319 -1.33422301  1.02362295 -1.07680692]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 125: -0.9999921833903868
Weights at Step 125: [ 5.91985767e-01 -1.57241251e-03  1.33882177e+00  1.79191152e+00
  8.89983556e-03 -8.53306759e-01]
Bias at Step 125: [-1.41164517 -1.34685868  1.0288417  -1.06603474]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 130: -0.9999895629847486
Weights at Step 130: [ 5.93396935e-01 -6.09903975e-04  1.32769014e+00  1.78340627e+00
  3.20989912e-03 -8.45936030e-01]
Bias at Step 130: [-1.41153989 -1.34372306  1.0306921  -1.06641934]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 135: -0.9999893671898544
Weights at Step 135: [ 5.93933082e-01 -1.84879055e-04  1.32433785e+00  1.77929886e+00
  4.38714188e-03 -8.45503125e-01]
Bias at Step 135: [-1.4098866  -1.34497204  1.03415862 -1.06007092]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 140: -0.999990999591533
Weights at Step 140: [ 0.5908483   0.00239647  1.33016899  1.78168215  0.00438378 -0.84478361]
Bias at Step 140: [-1.41145547 -1.35249113  1.0371159  -1.05630093]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 145: -0.9999882781659927
Weights at Step 145: [ 5.95379262e-01 -3.85481762e-04  1.33209614e+00  1.77901613e+00
 -1.07423798e-03 -8.40357066e-01]
Bias at Step 145: [-1.40745547 -1.35117282  1.03764696 -1.05779208]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 150: -0.9999882605157342
Weights at Step 150: [ 0.59753863 -0.00178702  1.33577445  1.78058366 -0.00414765 -0.83825161]
Bias at Step 150: [-1.40514789 -1.35375725  1.03826782 -1.05953418]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 155: -0.9999873092858327
Weights at Step 155: [ 5.96677467e-01  6.17989620e-04  1.34466485e+00  1.78402267e+00
 -2.65741532e-03 -8.41450495e-01]
Bias at Step 155: [-1.40789298 -1.356471    1.0376034  -1.05877886]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 160: -0.9999872637771742
Weights at Step 160: [ 0.60194839 -0.00191478  1.35123357  1.7884694  -0.00603744 -0.84142449]
Bias at Step 160: [-1.40510396 -1.35668892  1.03451132 -1.06543631]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 165: -0.9999874624869766
Weights at Step 165: [ 0.6030402  -0.00193504  1.34611742  1.78890714 -0.00577061 -0.84238872]
Bias at Step 165: [-1.40613555 -1.35445251  1.02812253 -1.07090041]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 170: -0.9999886747321689
Weights at Step 170: [ 0.5975333   0.00282116  1.32780927  1.78277225  0.00466827 -0.84919749]
Bias at Step 170: [-1.41126245 -1.34857858  1.02684163 -1.0645541 ]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 175: -0.999987556250722
Weights at Step 175: [ 0.59389571  0.00440434  1.32168971  1.78088367  0.00772899 -0.85019789]
Bias at Step 175: [-1.41279703 -1.34685714  1.02847119 -1.06186318]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 180: -0.9999914836764834
Weights at Step 180: [ 5.95476507e-01  1.04646713e-03  1.33253375e+00  1.78379408e+00
  1.79045580e-03 -8.45539923e-01]
Bias at Step 180: [-1.40924345 -1.34843997  1.03054894 -1.06465758]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 185: -0.9999877384049592
Weights at Step 185: [ 0.60021817 -0.00344807  1.34837992  1.78919267 -0.00485391 -0.84211998]
Bias at Step 185: [-1.40406354 -1.35059434  1.03159602 -1.06906187]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 190: -0.9999943811280623
Weights at Step 190: [ 0.60332647 -0.00502377  1.35580211  1.7937833  -0.00870162 -0.84089377]
Bias at Step 190: [-1.40248031 -1.35189812  1.02840358 -1.07489377]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 195: -0.9999899532834507
Weights at Step 195: [ 6.01661213e-01 -1.40258189e-03  1.34845381e+00  1.79177947e+00
 -2.19330435e-03 -8.46882171e-01]
Bias at Step 195: [-1.40624231 -1.34827409  1.02488298 -1.07228167]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 200: -0.9999880990041629
Weights at Step 200: [ 0.59781588  0.00262681  1.33622645  1.7903236   0.00491206 -0.85187394]
Bias at Step 200: [-1.41001483 -1.3468901   1.02276916 -1.06950677]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 205: -0.9999882388738662
Weights at Step 205: [ 0.59525242  0.00459556  1.33045933  1.78843797  0.00647584 -0.85208423]
Bias at Step 205: [-1.41193406 -1.34513748  1.02230177 -1.06854427]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 210: -0.9999848077040174
Weights at Step 210: [ 0.59407847  0.00331191  1.3261464   1.78462336  0.00583158 -0.84928496]
Bias at Step 210: [-1.40995186 -1.34363827  1.02517197 -1.06554306]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 215: -0.9999886167575431
Weights at Step 215: [ 5.93598280e-01  1.27457027e-03  1.32894414e+00  1.78302258e+00
  3.44879382e-03 -8.45638843e-01]
Bias at Step 215: [-1.40701621 -1.34498189  1.03023459 -1.06215846]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 220: -0.9999875727826187
Weights at Step 220: [ 5.94793970e-01 -8.57403942e-04  1.33609793e+00  1.78453102e+00
 -2.17937735e-03 -8.40640138e-01]
Bias at Step 220: [-1.40459538 -1.34840612  1.03328985 -1.06323676]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 225: -0.9999895237582316
Weights at Step 225: [ 0.59740767 -0.00202435  1.33963888  1.78462403 -0.00566848 -0.83842794]
Bias at Step 225: [-1.40352872 -1.34909283  1.03367034 -1.0646202 ]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 230: -0.999992221715183
Weights at Step 230: [ 0.59830589 -0.00184753  1.33406652  1.78177535 -0.00330205 -0.84015047]
Bias at Step 230: [-1.40427031 -1.34839966  1.03168677 -1.06292291]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 235: -0.9999912692867916
Weights at Step 235: [ 5.95836686e-01  8.57240159e-04  1.32786532e+00  1.78035155e+00
  2.56153005e-03 -8.44403818e-01]
Bias at Step 235: [-1.40725255 -1.34955664  1.03260437 -1.05840103]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 240: -0.999989935769989
Weights at Step 240: [ 0.59351612  0.00209534  1.32485259  1.77824259  0.00444528 -0.8447466 ]
Bias at Step 240: [-1.40903945 -1.35042747  1.03478287 -1.05550792]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 245: -0.9999889869569205
Weights at Step 245: [ 5.95395532e-01  1.23721713e-03  1.33593185e+00  1.78146341e+00
 -1.83303336e-03 -8.40987115e-01]
Bias at Step 245: [-1.40856761 -1.35225776  1.03748333 -1.05978839]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 250: -0.9999881293170488
Weights at Step 250: [ 5.95495047e-01 -2.18886873e-04  1.33760142e+00  1.78252108e+00
 -1.04388862e-03 -8.41650674e-01]
Bias at Step 250: [-1.40788422 -1.35473503  1.03617744 -1.05980154]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 255: -0.9999892613809336
Weights at Step 255: [ 5.95095996e-01  1.05345945e-03  1.33120954e+00  1.78110699e+00
  9.09621038e-04 -8.43176791e-01]
Bias at Step 255: [-1.40881827 -1.35271576  1.03732158 -1.05936317]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 260: -0.9999911696516827
Weights at Step 260: [ 0.59215329  0.00249312  1.32162048  1.77469111  0.00411753 -0.84385295]
Bias at Step 260: [-1.41164782 -1.34921326  1.03505213 -1.05565234]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 265: -0.9999897602169295
Weights at Step 265: [ 5.94219509e-01  1.15801805e-03  1.32981272e+00  1.77875998e+00
  2.00797690e-03 -8.43338459e-01]
Bias at Step 265: [-1.40879199 -1.35161558  1.04052305 -1.05548315]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 270: -0.9999877865048057
Weights at Step 270: [ 0.5967199  -0.00228699  1.34015592  1.78207987 -0.00207472 -0.8407702 ]
Bias at Step 270: [-1.40654726 -1.35550984  1.03685756 -1.05892969]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 275: -0.9999913148930893
Weights at Step 275: [ 5.95115179e-01  6.67458889e-04  1.33088691e+00  1.77908492e+00
  2.17950090e-03 -8.43784743e-01]
Bias at Step 275: [-1.40907272 -1.35232601  1.03787329 -1.05577319]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 280: -0.9999912773773975
Weights at Step 280: [ 5.94534323e-01  1.49825127e-03  1.33221200e+00  1.78129607e+00
  1.80930063e-03 -8.43864609e-01]
Bias at Step 280: [-1.41032893 -1.35393432  1.03609549 -1.0579392 ]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 285: -0.9999871922879657
Weights at Step 285: [ 5.96437497e-01  3.12450031e-04  1.33601315e+00  1.78353853e+00
 -7.60576311e-04 -8.42698914e-01]
Bias at Step 285: [-1.40896079 -1.3539148   1.03483345 -1.06189856]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 290: -0.9999918144420525
Weights at Step 290: [ 0.5928268   0.00288728  1.32568915  1.77748739  0.00484885 -0.84553166]
Bias at Step 290: [-1.41115856 -1.34928842  1.03616776 -1.0560555 ]
---------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost at Step 295: -0.9999908668757235
Weights at Step 295: [ 5.95067478e-01  6.59873700e-06  1.33530656e+00  1.78268285e+00
 -6.83963342e-04 -8.41953097e-01]
Bias at Step 295: [-1.40781716 -1.35320774  1.03673384 -1.06074438]
---------------------------------------------
</pre></div>
</div>
</div>
</div>
<p>With the learned parameters, we construct a visual representation of the Hamiltonian to which they correspond and compare it to the target Hamiltonian, and the initial guessed Hamiltonian:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_ham_matrix</span> <span class="o">=</span> <span class="n">create_hamiltonian_matrix</span><span class="p">(</span>
    <span class="n">qubit_number</span><span class="p">,</span> <span class="n">nx</span><span class="o">.</span><span class="n">complete_graph</span><span class="p">(</span><span class="n">qubit_number</span><span class="p">),</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span>
<span class="p">)</span>

<span class="n">init_ham</span> <span class="o">=</span> <span class="n">create_hamiltonian_matrix</span><span class="p">(</span>
    <span class="n">qubit_number</span><span class="p">,</span> <span class="n">nx</span><span class="o">.</span><span class="n">complete_graph</span><span class="p">(</span><span class="n">qubit_number</span><span class="p">),</span> <span class="n">initial_weights</span><span class="p">,</span> <span class="n">initial_bias</span>
<span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">ham_matrix</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">7</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;hot&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Target&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.13</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">init_ham</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">7</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;hot&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Initial&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.13</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">new_ham_matrix</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">7</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;hot&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Learned&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.13</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../../_images/afd108184dc46054825a0ff097b4fd6c63fa93893b4fa1872fe7b27cffde5d29.png" src="../../../../_images/afd108184dc46054825a0ff097b4fd6c63fa93893b4fa1872fe7b27cffde5d29.png" />
</div>
</div>
<p>These images look very similar, indicating that the QGRNN has done a good job learning the target Hamiltonian.</p>
<p>We can also look at the exact values of the target and learned parameters. Recall how the target interaction graph has <span class="math notranslate nohighlight">\(4\)</span> edges while
the complete graph has <span class="math notranslate nohighlight">\(6\)</span>. Thus, as the QGRNN converges to the optimal solution, the weights corresponding to edges <span class="math notranslate nohighlight">\((1, 3)\)</span> and <span class="math notranslate nohighlight">\((2, 0)\)</span> in
the complete graph should go to <span class="math notranslate nohighlight">\(0\)</span>, as this indicates that they have no effect, and effectively do not exist in the learned Hamiltonian.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We first pick out the weights of edges (1, 3) and (2, 0)</span>
<span class="c1"># and then remove them from the list of target parameters</span>

<span class="n">weights_noedge</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">weights_edge</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">edge</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">new_ising_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">edge</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">qubit_number</span><span class="p">,</span> <span class="n">edge</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">qubit_number</span><span class="p">)</span> <span class="ow">in</span> <span class="n">ising_graph</span><span class="o">.</span><span class="n">edges</span><span class="p">:</span>
        <span class="n">weights_edge</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">weights_noedge</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Then, we print all of the weights:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Target parameters     Learned parameters&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Weights&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">41</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ii_target</span><span class="p">,</span> <span class="n">ii_learned</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">target_weights</span><span class="p">,</span> <span class="n">weights_edge</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">ii_target</span> <span class="si">:</span><span class="s2"> &lt;20</span><span class="si">}</span><span class="s2">|</span><span class="si">{</span><span class="n">ii_learned</span> <span class="si">:</span><span class="s2"> &gt;20</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Bias&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">41</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ii_target</span><span class="p">,</span> <span class="n">ii_learned</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">target_bias</span><span class="p">,</span> <span class="n">bias</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">ii_target</span> <span class="si">:</span><span class="s2"> &lt;20</span><span class="si">}</span><span class="s2">|</span><span class="si">{</span><span class="n">ii_learned</span> <span class="si">:</span><span class="s2"> &gt;20</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Non-Existing Edge Parameters: </span><span class="si">{</span><span class="p">[</span><span class="n">val</span><span class="o">.</span><span class="n">unwrap</span><span class="p">()</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">weights_noedge</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Target parameters     Learned parameters
Weights
-----------------------------------------
0.56                |  0.5988034096092832
1.24                |  1.3483865512005249
1.67                |   1.786207064845589
-0.79               | -0.8425475506159178

Bias
-----------------------------------------
-1.44               | -1.4067983643944113
-1.43               | -1.3529638627173919
1.18                |   1.034912941983086
-0.93               |  -1.063587496659968

Non-Existing Edge Parameters: [-0.0012651471928199864, -0.003653447242327378]
</pre></div>
</div>
</div>
</div>
<p>The weights of edges <span class="math notranslate nohighlight">\((1, 3)\)</span> and <span class="math notranslate nohighlight">\((2, 0)\)</span> are very close to <span class="math notranslate nohighlight">\(0\)</span>, indicating we have learned the cycle graph from the complete graph. In addition, the remaining learned weights are fairly close to those of the
target Hamiltonian. Thus, the QGRNN is functioning properly, and has learned the target Ising Hamiltonian to a high degree of accuracy!</p>
</section>
<section id="id1">
<h2>Send it after class:<a class="headerlink" href="#id1" title="Permalink to this heading">¶</a></h2>
<p>The imaginary-time evolution method is a well-known approach used for obtaining the ground state in quantum many-body problems (see https://physics.stackexchange.com/questions/557225/why-do-we-use-the-imaginary-time-evolution-in-simulations-of-some-quantum-system)</p>
<p>Find the ground state of a quadratic Hamiltonian (i.e. something in the class of traverse field Ising model) using imaginary time evolution</p>
</section>
</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="../../../../_sources/courses/PHYS710/hands-on/hands-on-10/hands-on-10-book.ipynb.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright (CC BY 3.0) https://creativecommons.org/ .<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.3.0.<br/>
    </p>
  </div>
</footer>
  </body>
</html>